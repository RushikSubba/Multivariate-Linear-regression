{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost :  0.0033736656099699015\n",
      "Eabs : 3.285329010719529\n",
      "Erms : 0.36834115812844703\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Multivariate Linear Regression\n",
    "    ---with lasso and ridge regularization\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "    Squared Error\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta \n",
    "        lb     : lambda value for regularization\n",
    "        reg    : regularization function\n",
    "\n",
    "\"\"\"\n",
    "def cost(x, y, th, lb, reg):\n",
    "    diff = x @ th - y\n",
    "    t = (1 / (2 * x.shape[0])) * diff.transpose() @ diff + (0 if reg == None else reg(lb, th))\n",
    "    ans = np.squeeze(t)\n",
    "    return ans\n",
    "\n",
    "\"\"\"\n",
    "    Gradient Descent\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta\n",
    "        lb     : lambda value for regularization\n",
    "        reg    : regularization function\n",
    "        regder : regularization function derivative\n",
    "\"\"\"\n",
    "def gr_dsc(x, y, th, lb = 0, reg = None, regder = None):\n",
    "    iters = 10000\n",
    "    alpha = 0.001\n",
    "    while(iters != 0) :\n",
    "        th = th - alpha*(x.transpose() @ (x @ th - y) + (0 if regder == None else regder(lb, th)))\n",
    "        iters -= 1\n",
    "    print(\"Cost : \", cost(x,y,th,lb, reg))\n",
    "    \n",
    "\"\"\"\n",
    "    Lasso regularization\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def lasso_reg(lb, th):\n",
    "    a = 0;\n",
    "    for i in th:\n",
    "        a = a + abs(i)\n",
    "    return a * lb\n",
    "\n",
    "\"\"\"\n",
    "    Lasso regularization derivative\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def lasso_regder(lb, th):\n",
    "    return lb * th / abs(th)\n",
    "\n",
    "\"\"\"\n",
    "    Ridge regularization\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def ridge_reg(lb, th):\n",
    "    return (lb / 2) * np.squeeze(th.transpose() @ th)\n",
    "\n",
    "\"\"\"\n",
    "    Ridge regularization derivative\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def ridge_regder(lb, th):\n",
    "    return lb * th\n",
    "\n",
    "\"\"\"\n",
    "    Plots Cost vs theta(i) for all theta\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta\n",
    "\"\"\"\n",
    "def plotter(x, y, th):\n",
    "    ti = np.linspace(-10, 10, num=1000)\n",
    "    for i in range(th.shape[0]):\n",
    "        th1 = np.copy(th)\n",
    "        jv = []\n",
    "        for j in ti:\n",
    "            th1[i][0] = j\n",
    "            jv.append(cost(x, y, th1))\n",
    "        print(min(jv))\n",
    "        plt.plot(ti, jv)\n",
    "        plt.show()\n",
    "        \n",
    "\"\"\"\n",
    "    Error calculation\n",
    "        x      : testing data\n",
    "        y      : outputs\n",
    "        th     : theta \n",
    "\"\"\"\n",
    "\n",
    "def error_calculations(x, y, th):\n",
    "    diff = x @ th - y\n",
    "    sum_of_squared_errors = diff.transpose() @ diff\n",
    "    Eabs = sum(np.absolute(diff)) / x.shape[0]\n",
    "    Erms = math.sqrt(sum_of_squared_errors[0][0]) / x.shape[0]\n",
    "    print(\"Eabs : {}\".format(Eabs[0]))\n",
    "    print(\"Erms : {}\".format(Erms))\n",
    "    \n",
    "    \n",
    "#file name for data\n",
    "f_name = \"real_estate.csv\"\n",
    "data = np.genfromtxt(f_name, delimiter=\",\", skip_header=1)\n",
    "\n",
    "rows = data.shape[0]\n",
    "columns = data.shape[1]\n",
    "\n",
    "th = np.ones((columns, 1))\n",
    "x = np.ones((rows, columns))\n",
    "y = np.zeros((rows, 1))\n",
    "\n",
    "#min and max for all columns\n",
    "mins = data.min(axis=0)\n",
    "maxs = data.max(axis=0)\n",
    "\n",
    "#normalize\n",
    "for i in range(columns):\n",
    "    if i == columns - 1:\n",
    "        for j in range(rows):\n",
    "            y[j][0] = (data[j][i] - mins[i])/(maxs[i] - mins[i])\n",
    "    else :\n",
    "        for j in range(rows):\n",
    "            x[j][i + 1] = (data[j][i] - mins[i])/(maxs[i] - mins[i])\n",
    "\n",
    "#splitting into learning and testing sets\n",
    "x_learning = x[:int(0.8*rows) + 1,:]\n",
    "x_testing = x[int(0.8*rows) + 1:,:]\n",
    "y_learning = y[:int(0.8*rows) + 1,:]\n",
    "y_testing = y[int(0.8*rows) + 1:,:]\n",
    "th_copy = th.copy()\n",
    "\n",
    "gr_dsc(x_learning, y_learning, th_copy)\n",
    "\n",
    "error_calculations(x_testing, y_testing, th_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
