{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Multivariate Linear Regression\n",
    "    ---with lasso and ridge regularization\n",
    "    ---with Z-Score and min-max normalization\n",
    "    ---plotted contour of theta(1) and theta(2) with respect to cost function\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Command Line Input :\n",
    "        python3 mvlr.py [filename] [number of rows to be skipped (default=1)] [delimiter (default=space)]\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math, sys\n",
    "\n",
    "\"\"\"\n",
    "    Squared Error\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta \n",
    "        lb     : lambda value for regularization\n",
    "        reg    : regularization function\n",
    "\n",
    "\"\"\"\n",
    "def cost(x, y, th, lb = 0, reg = None):\n",
    "    diff = x @ th - y\n",
    "    return np.squeeze((1 / (2 * x.shape[0])) * diff.transpose() @ diff + (0 if reg == None else reg(lb, th)))\n",
    "\n",
    "\"\"\"\n",
    "    Gradient Descent\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta\n",
    "        iters  : no of iterations\n",
    "        alpha  : learning rate\n",
    "        lb     : lambda value for regularization\n",
    "        reg    : regularization function\n",
    "        regder : regularization function derivative\n",
    "\"\"\"\n",
    "def gr_dsc(x, y, th, iters = 10000, alpha = 0.001, lb = 0, reg = None, regder = None):\n",
    "    iter_ = iters\n",
    "    while(iters != 0) :\n",
    "        th = th - alpha*(x.transpose() @ (x @ th - y) + (0 if regder == None else regder(lb, th)))\n",
    "        iters -= 1\n",
    "    print(\"After \" + str(iter_) + \" iterations with alpha = \" + str(alpha) + \",Cost = \" + str(cost(x, y, th, lb, reg)))\n",
    "    return th\n",
    "\n",
    "\"\"\"\n",
    "    Lasso regularization\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def lasso_reg(lb, th):\n",
    "    return abs(th).sum() * lb\n",
    "\"\"\"\n",
    "    Lasso regularization derivative\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def lasso_regder(lb, th):\n",
    "    return lb * th / abs(th)\n",
    "\n",
    "\"\"\"\n",
    "    Ridge regularization\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def ridge_reg(lb, th):\n",
    "    return (lb / 2) * np.squeeze(th.transpose() @ th)\n",
    "\n",
    "\"\"\"\n",
    "    Ridge regularization derivative\n",
    "        th : theta\n",
    "        lb : lambda value for regularization\n",
    "\"\"\"\n",
    "def ridge_regder(lb, th):\n",
    "    return lb * th\n",
    "\n",
    "\"\"\"\n",
    "    Plots Cost vs theta(i) for all theta\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta\n",
    "\"\"\"\n",
    "def plotter(x, y, th):\n",
    "    ti = np.linspace(-10, 10, num=1000)\n",
    "    for i in range(th.shape[0]):\n",
    "        th1 = np.copy(th)\n",
    "        jv = []\n",
    "        for j in ti:\n",
    "            th1[i][0] = j\n",
    "            jv.append(cost(x, y, th1))\n",
    "        print(min(jv))\n",
    "        plt.plot(ti, jv)\n",
    "        plt.show()\n",
    "\n",
    "\"\"\"\n",
    "    Contour plots\n",
    "        x      : training data\n",
    "        y      : outputs\n",
    "        th     : theta\n",
    "\"\"\"\n",
    "def contour(x, y, th):\n",
    "    th1 = np.linspace(-1000, 1000, num=1000)\n",
    "    th2 = np.linspace(-1000, 1000, num=1000)\n",
    "    TH1, TH2 = np.meshgrid(th1, th2)\n",
    "    \n",
    "    th_copy = th.copy()\n",
    "    jv = np.zeros((len(th1), len(th2)))\n",
    "    for i in range(0,len(th1)):\n",
    "        th_copy[1][0] = th1[i]\n",
    "        for j in range(0, len(th2)):\n",
    "            th_copy[2][0] = th2[j]\n",
    "            jv[i][j] = cost(x, y, th_copy)\n",
    "    \n",
    "    plt.contour(TH1, TH2, jv)\n",
    "    plt.show()\n",
    "            \n",
    "    \n",
    "\"\"\"\n",
    "    Error calculation\n",
    "        x      : testing data\n",
    "        y      : outputs\n",
    "        th     : theta \n",
    "\"\"\"\n",
    "def error_calculations(x, y, th):\n",
    "    diff = x @ th - y\n",
    "    sum_of_squared_errors = diff.transpose() @ diff\n",
    "    Eabs = sum(np.absolute(diff)) / x.shape[0]\n",
    "    Erms = math.sqrt(sum_of_squared_errors[0][0]) / x.shape[0]\n",
    "    print(\"Eabs = {}\".format(Eabs[0]))\n",
    "    print(\"Erms = {}\".format(Erms))\n",
    "\n",
    "\"\"\"\n",
    "    Min-Max normalization\n",
    "        x      : non normalized data\n",
    "        y      : non normalized output\n",
    "        data   : data to be normalized \n",
    "\"\"\"     \n",
    "def min_max_norm(x, y, x_normalized, y_normalized, data):\n",
    "    rows = data.shape[0]\n",
    "    columns = data.shape[1]\n",
    "    \n",
    "    mins = data.min(axis=0)\n",
    "    maxs = data.max(axis=0)\n",
    "\n",
    "    for i in range(columns):\n",
    "        if i == columns - 1:\n",
    "            for j in range(rows):\n",
    "                y_normalized[j][0] = (data[j][i] - mins[i])/(maxs[i] - mins[i])\n",
    "                y[j][0] = data[j][i]\n",
    "        else :\n",
    "            for j in range(rows):\n",
    "                x_normalized[j][i + 1] = (data[j][i] - mins[i])/(maxs[i] - mins[i])\n",
    "                x[j][i + 1] = data[j][i]\n",
    "\n",
    "\"\"\"\n",
    "    Z-Score Normalization\n",
    "        x      : non normalized data\n",
    "        y      : non normalized output\n",
    "        data   : data to be normalized\n",
    "\"\"\"\n",
    "def z_score_norm(x, y, x_normalized, y_normalized, data):\n",
    "    rows = data.shape[0]\n",
    "    columns = data.shape[1]\n",
    "    \n",
    "    means = data.mean(axis = 0)\n",
    "    std = data.std(axis = 0)\n",
    "    \n",
    "    for i in range(columns):\n",
    "        if i == columns - 1:\n",
    "            for j in range(rows):\n",
    "                y_normalized[j][0] = (data[j][i] - means[i])/(std[i])\n",
    "                y[j][0] = data[j][i]\n",
    "        else :\n",
    "            for j in range(rows):\n",
    "                x_normalized[j][i + 1] = (data[j][i] - means[i])/(std[i])\n",
    "                x[j][i + 1] = data[j][i]\n",
    "\n",
    "#Command line arguments\n",
    "argList = sys.argv \n",
    "f_name = argList[1]\n",
    "delim = \" \"\n",
    "skp_head = 1\n",
    "\n",
    "if(len(argList) > 2):\n",
    "    skp_head = int(argList[2])\n",
    "if(len(argList) > 3):\n",
    "    delim = argList[3]\n",
    "\n",
    "#Initializing the input data\n",
    "data = np.genfromtxt(f_name, delimiter=delim, skip_header=skp_head)\n",
    "rows = data.shape[0]\n",
    "columns = data.shape[1]\n",
    "\n",
    "#Initializing the X, Y and Theta\n",
    "th = np.ones((columns, 1))\n",
    "x = np.ones((rows, columns))\n",
    "y = np.zeros((rows, 1))\n",
    "x_normalized = np.ones((rows, columns))\n",
    "y_normalized = np.zeros((rows, 1))\n",
    "\n",
    "#Normalize\n",
    "opt = int(input(\"Enter 1 for Min-Max norm, 2 for Z-Score : \"))\n",
    "if(opt == 1):\n",
    "    min_max_norm(x, y, x_normalized, y_normalized, data)\n",
    "elif(opt == 2):\n",
    "    z_score_norm(x, y, x_normalized, y_normalized, data)\n",
    "\n",
    "#Splitting into learning and testing sets\n",
    "x_learning = x_normalized[:int(0.8*rows) + 1,:]\n",
    "x_testing = x_normalized[int(0.8*rows) + 1:,:]\n",
    "y_learning = y_normalized[:int(0.8*rows) + 1,:]\n",
    "y_testing = y_normalized[int(0.8*rows) + 1:,:]\n",
    "th_copy = th.copy()\n",
    "\n",
    "#Produce Contours\n",
    "print(\"Normalized countour : \")\n",
    "print(\"Close the contour window to continue...\")\n",
    "contour(x_normalized, y_normalized, th_copy)\n",
    "print(\"Non-Normalized countour : \")\n",
    "print(\"Close the contour window to continue...\")\n",
    "contour(x, y, th_copy)\n",
    "\n",
    "reg = None\n",
    "regder = None\n",
    "opt = int(input(\"Enter 1 for lasso regularization, 2 for ridge regularizations, 3 for none \"))\n",
    "if(opt == 1):\n",
    "    reg = lasso_reg\n",
    "    reg_der = lasso_regder\n",
    "elif(opt == 2):\n",
    "    reg = ridge_reg\n",
    "    reg_der = ridge_regder\n",
    "\n",
    "th_copy = gr_dsc(x_learning, y_learning, th_copy, iters = 10000, alpha = 0.002, lb = 0.01, reg = reg, regder = regder)\n",
    "error_calculations(x_testing, y_testing, th_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
